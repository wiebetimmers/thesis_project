{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EA(object):\n",
    "    def __init__(self,  population_size, val_loader, loss_function, input_size, reservoir_size, n_labels):\n",
    "        self.population_size = population_size\n",
    "        self.val_loader = val_loader\n",
    "        self.loss_function = loss_function\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = n_labels\n",
    "\n",
    "    def fitness(self, population, parents=None):\n",
    "        \n",
    "        # Copy paste the last results, so we don't have to calculate the loss and accuracy of an unchanged model. \n",
    "        if parents == True:\n",
    "            for reservoir in population:\n",
    "                reservoir['epoch'].append(reservoir['epoch'][-1]+1)\n",
    "                reservoir['loss_results'].append(reservoir['loss_results'][-1])\n",
    "                reservoir['class_error_results'].append(reservoir['class_error_results'][-1])\n",
    "            \n",
    "        else:\n",
    "            # Evaluate the performance of every (mutated/recombinated) model in the population,\n",
    "            # add the results to results list. \n",
    "            for reservoir in population:\n",
    "                epoch, loss, total_accuracy = evaluation(self.val_loader, \n",
    "                                                         reservoir['model'], \n",
    "                                                         reservoir['epoch'][-1]+1, \n",
    "                                                         loss_function)\n",
    "                reservoir['epoch'].append(epoch)\n",
    "                reservoir['loss_results'].append(loss)\n",
    "                reservoir['class_error_results'].append(total_accuracy)\n",
    "\n",
    "                # If we find a new best model, save it.\n",
    "                # Still have to fine tune this , make a directory for all the models. \n",
    "                '''if loss < reservoir['best_loss']:\n",
    "                    print('* Saving new best model *')\n",
    "                    torch.save(reservoir['model'], 'trained_reservoir.model')\n",
    "                    reservoir['best_loss'] = loss\n",
    "                    reservoir['loss_iter'] = 0\n",
    "                else:\n",
    "                    reservoir['loss_iter'] += 1'''\n",
    "\n",
    "        return population\n",
    "\n",
    "    def mutation(self, pop, option, offspring_ratio, sample_dist, perturb_rate):\n",
    "        # Lets pick an offspring ratio of 3 to 1 parent\n",
    "        \n",
    "        if option == 'random_perturbation':\n",
    "            mut_pop = self.random_perturbation(pop, sample_dist)\n",
    "            print('Parent / child ratio = 1 : %s' %offspring_ratio)\n",
    "            \n",
    "            if offspring_ratio >1:\n",
    "                for i in range(offspring_ratio - 1):\n",
    "                    mut_pop += self.random_perturbation(pop, sample_dist)\n",
    "        \n",
    "        elif option == 'diff_mutation':\n",
    "            perturb_rate = perturb_rate\n",
    "            mut_pop = self.diff_mutation(pop, perturb_rate)\n",
    "            \n",
    "            if offspring_ratio >1:\n",
    "                for i in range(offspring_ratio - 1):\n",
    "                    mut_pop += self.diff_mutation(pop, perturb_rate)\n",
    "            \n",
    "        \n",
    "        return mut_pop \n",
    "    \n",
    "    def diff_mutation(self, pop, perturb_rate):\n",
    "        mut_pop = copy.deepcopy(pop)\n",
    "        \n",
    "        for reservoir in mut_pop:\n",
    "            \n",
    "            # Randomly sample 2 models from the population & split them up\n",
    "            sample = random.sample(pop, 2)\n",
    "            sample1 = sample[0]['model']\n",
    "            sample2 = sample[1]['model']\n",
    "            \n",
    "            # Perturb the weights\n",
    "            reservoir['model'].layer1.weight +=  perturb_rate * (sample1.layer1.weight - sample2.layer1.weight)\n",
    "            reservoir['model'].layer2.weight += perturb_rate * (sample1.layer2.weight - sample2.layer2.weight)\n",
    "            reservoir['model'].layer3.weight += perturb_rate * (sample1.layer3.weight - sample2.layer3.weight)\n",
    "            temp_w_out = reservoir['model'].layer4.weight + perturb_rate * (sample1.layer4.weight - sample2.layer4.weight)\n",
    "            reservoir['model'].layer4.weight = nn.Parameter(temp_w_out, requires_grad = False)\n",
    "        \n",
    "        return mut_pop\n",
    "    \n",
    "    def random_perturbation(self, pop, sample_dist):\n",
    "        mut_pop = copy.deepcopy(pop)\n",
    "        \n",
    "        for reservoir in mut_pop:\n",
    "            if sample_dist == 'uniform':\n",
    "                W_in_sample = torch.empty(self.reservoir_size, self.input_size).uniform_(-0.01, 0.01)\n",
    "                W_r_sample = torch.empty(self.reservoir_size, self.reservoir_size).uniform_(-0.01, 0.01)\n",
    "                W_out_sample = torch.empty(self.output_size, self.reservoir_size).uniform_(-0.01, 0.01)\n",
    "                U_sample = torch.empty(self.reservoir_size, self.input_size).uniform_(-0.01, 0.01)\n",
    "            \n",
    "            elif sample_dist == 'gaussian':\n",
    "                W_in_sample = torch.empty(self.reservoir_size, self.input_size).normal_(0, 0.05)\n",
    "                W_r_sample = torch.empty(self.reservoir_size, self.reservoir_size).normal_(0, 0.05)\n",
    "                W_out_sample = torch.empty(self.output_size, self.reservoir_size).normal_(0, 0.05)\n",
    "                U_sample = torch.empty(self.reservoir_size, self.input_size).normal_(0, 0.05)\n",
    "            \n",
    "            reservoir['model'].layer1.weight = nn.Parameter(W_in_sample, requires_grad = False)\n",
    "            reservoir['model'].layer2.weight = nn.Parameter(W_r_sample, requires_grad = False)\n",
    "            reservoir['model'].layer3.weight = nn.Parameter(U_sample, requires_grad = False)\n",
    "            \n",
    "            # We have to turn off requires grad,\n",
    "            # because pytorch does not allow inplace mutations on tensors which are used for backprop.\n",
    "            # See https://discuss.pytorch.org/t/leaf-variable-was-used-in-an-inplace-operation/308/2 .\n",
    "            reservoir['model'].layer4.weight = nn.Parameter(W_out_sample, requires_grad = False)\n",
    "        \n",
    "        return mut_pop \n",
    "    \n",
    "    def parent_offspring_selection(self, pop, recomb_pop, option):\n",
    "        # Merge parents and childs\n",
    "        total_pop = pop + recomb_pop\n",
    "        \n",
    "        # Select the top performing (lowest loss)\n",
    "        if option == 'loss':\n",
    "            total_pop = sorted(total_pop, key=lambda k: k['loss_results'][-1]) \n",
    "            new_pop = total_pop[:len(pop)]\n",
    "            \n",
    "        # Select the top performing (lowest classification error)\n",
    "        elif option == 'classification_error':\n",
    "            total_pop = sorted(total_pop, key=lambda k: k['class_error_results'][-1], reverse=False) \n",
    "            new_pop = total_pop[:len(pop)]\n",
    "            \n",
    "        return new_pop\n",
    "    \n",
    "    def keep_best_selection(self, pop, offspring, option, k_best):\n",
    "        \n",
    "        offspring_best = len(pop) - k_best\n",
    "        \n",
    "        # Select the top performing (lowest classification error)\n",
    "        pop_sorted = sorted(pop, key=lambda k: k['class_error_results'][-1], reverse=False) \n",
    "        best_pop = pop_sorted[:k_best]\n",
    "        \n",
    "        offspring_sorted = sorted(offspring, key=lambda k: k['class_error_results'][-1], reverse=False)\n",
    "        best_offspring = offspring_sorted[:offspring_best]\n",
    "        \n",
    "        new_pop = best_pop + best_offspring\n",
    "        print('test selection')\n",
    "        \n",
    "        \n",
    "        return new_pop\n",
    "    \n",
    "    def crossover(self, pop):\n",
    "        \n",
    "        # Using random crossover\n",
    "        \n",
    "        crossed_pop = copy.deepcopy(pop)\n",
    "        \n",
    "        W_in = []\n",
    "        W_r = []\n",
    "        U = []\n",
    "        W_out = []\n",
    "        \n",
    "        \n",
    "        # From parent population\n",
    "        for reservoir in pop:\n",
    "            W_in.append(reservoir['model'].layer1.weight)\n",
    "            W_r.append(reservoir['model'].layer2.weight)\n",
    "            U.append(reservoir['model'].layer3.weight)\n",
    "            W_out.append(reservoir['model'].layer4.weight)\n",
    "        \n",
    "        # crossover\n",
    "        for reservoir in crossed_pop:\n",
    "            reservoir['model'].layer1.weight = random.choice(W_in)\n",
    "            reservoir['model'].layer3.weight = random.choice(U)\n",
    "            reservoir['model'].layer2.weight = random.choice(W_r)\n",
    "            reservoir['model'].layer4.weight = random.choice(W_out)\n",
    "        \n",
    "        return crossed_pop\n",
    "             \n",
    "    def selection(self, pop, offspring, option, select_mech, k_best):\n",
    "        \n",
    "        # Parents + offspring selection\n",
    "        if select_mech == 'merge_all':\n",
    "            new_pop = self.parent_offspring_selection(pop, offspring, option)\n",
    "        elif select_mech == 'keep_k_best':\n",
    "            new_pop = self.keep_best_selection(pop, offspring, option, k_best)\n",
    "        \n",
    "        return new_pop\n",
    "    \n",
    "    def step(self, pop, mutate_opt, perturb_rate, select_opt, select_mech, offspring_ratio, sample_dist, k_best):\n",
    "        \n",
    "        # Apply some mutation and recombination\n",
    "        mut_pop = self.mutation(pop, mutate_opt, offspring_ratio, sample_dist, perturb_rate)\n",
    "        crossed_pop = self.crossover(mut_pop)\n",
    "        \n",
    "        # Merge (mutated pop) + (mutated AND crossed pop), so we have a larger pool to pick from. \n",
    "        merged_pop = mut_pop + crossed_pop\n",
    "        \n",
    "        # Get fitness from parents \n",
    "        pop = self.fitness(pop, parents=True)\n",
    "        \n",
    "        # Get fitness from childs\n",
    "        print('Possible candidates for optimization')\n",
    "        merged_pop = self.fitness(merged_pop, parents=False)\n",
    "            \n",
    "        # Survivor selection\n",
    "        new_pop = self.selection(pop, merged_pop, select_opt, select_mech, k_best)\n",
    "        \n",
    "        return new_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
