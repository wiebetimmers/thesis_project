{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that transforms the tensor output to a predicted target name. \n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return LABELS[category_i]\n",
    "    \n",
    "# Plot both accuracy as log loss. \n",
    "def plot_results(epochs, loss, accuracy, title):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle('%s' %title)\n",
    "    ax1.set(ylabel='Loss')\n",
    "    ax2.set(ylabel='Accuracy', xlabel='Epochs')\n",
    "    \n",
    "    ax1.plot(epochs, loss)\n",
    "    ax2.plot(epochs, accuracy)\n",
    "    plt.savefig('%s.png' %(title), bbox_inches='tight')\n",
    "    return\n",
    "\n",
    "def combined_plot_result(epochs, loss_bl, accuracy_bl,  \n",
    "                                 loss_res, accuracy_res,\n",
    "                                 loss_evo, accuracy_evo,\n",
    "                                 border = None,\n",
    "                                 label_bl='', label_res='', label_evo= '', title=''):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle('%s' %title)\n",
    "    ax1.set(ylabel='Loss', xlabel='Epochs')\n",
    "    ax2.set(ylabel='Accuracy', xlabel='Epochs')\n",
    "    \n",
    "    ax1.plot(epochs, loss_bl, label=label_bl)\n",
    "    ax1.plot(epochs, loss_res, label=label_res)\n",
    "    ax1.plot(epochs, loss_evo, label=label_evo)\n",
    "    ax2.plot(epochs, accuracy_bl, label=label_bl)\n",
    "    ax2.plot(epochs, accuracy_res, label=label_res)\n",
    "    ax2.plot(epochs, accuracy_evo, label=label_evo)\n",
    "    \n",
    "    if border != None:\n",
    "        ax1.axvline(border, label='EA optimizing start', c='r')\n",
    "        ax2.axvline(border, label='EA optimizing start', c='r')\n",
    "    \n",
    "    ax1.legend(loc='upper right')\n",
    "    ax2.legend(loc='lower right')\n",
    "    \n",
    "    plt.savefig('multiple_results.png', bbox_inches='tight')\n",
    "    \n",
    "    return\n",
    "\n",
    "# Concatenating the results of all (64*)batches in the lists, calculating the total accuracy. \n",
    "def accuracy(pred_targets_list, gold_targets_list):\n",
    "    total_correct = 0\n",
    "    total_amount = 0\n",
    "    \n",
    "    zip_list = zip(pred_targets_list, gold_targets_list)\n",
    "    for pred_targets, gold_targets in zip_list:\n",
    "        total_correct += (pred_targets == gold_targets).float().sum()\n",
    "        total_amount += len(pred_targets)\n",
    "    \n",
    "    accuracy = 100 * total_correct / total_amount\n",
    "\n",
    "    return accuracy.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation -> used for validation and test set. \n",
    "def evaluation(val_loader, model, epoch, loss_function):\n",
    "    \n",
    "    #Evaluating our performance so far\n",
    "    model.eval()\n",
    "    \n",
    "    # Store all results in a list to calculate the accuracy. \n",
    "    pred_target_total_acc = []\n",
    "    target_total_acc = []\n",
    "    \n",
    "    # Initialize counters / c\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    \n",
    "    # Iterating over the validation set batches, acquiring tensor formatted results. \n",
    "    for indx_batch, (batch, targets) in enumerate(val_loader):\n",
    "        output = model.forward(batch)\n",
    "        pred_targets = np.array([])\n",
    "        for item in output:\n",
    "            pred_targets = np.append(pred_targets, categoryFromOutput(item))\n",
    "        pred_targets = torch.from_numpy(pred_targets).int()\n",
    "        \n",
    "        # Calculating loss\n",
    "        loss_t = loss_function(output, targets.long())\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + batch.shape[0]\n",
    "        \n",
    "        #Append the batch result to a list of all results\n",
    "        pred_target_total_acc.append(pred_targets)\n",
    "        target_total_acc.append(targets)\n",
    "    \n",
    "    # Store the loss corrected by its size\n",
    "    loss = loss / N   \n",
    "        \n",
    "    total_accuracy = accuracy(pred_target_total_acc, target_total_acc)\n",
    "    print('Epoch: %s - Loss of: %s - Accuracy of: %s' %(epoch, loss,total_accuracy))\n",
    "    \n",
    "    return epoch, loss, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_control(epoch, model, best_loss, loss_eval, loss_iter, max_loss_iter):\n",
    "    if epoch == 0:\n",
    "        #print('* Saving 1st epoch model *')\n",
    "        #torch.save(model, 'trained_baseline.model')\n",
    "        best_loss = loss_eval\n",
    "    else:\n",
    "        if loss_eval < best_loss:\n",
    "            #print('* Saving new best model *')\n",
    "            #torch.save(model, 'trained_baseline.model')\n",
    "            best_loss = loss_eval\n",
    "            loss_iter = 0\n",
    "        else:\n",
    "            loss_iter += 1\n",
    "        \n",
    "    # If loss has not improved for an arbitrary amount of epochs:\n",
    "    # if loss_iter > max_loss_iter:\n",
    "\n",
    "        \n",
    "    return best_loss, loss_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_loader, val_loader, num_epochs, optimizer, loss_function, max_loss_iter, baseline=True):    \n",
    "    \n",
    "    print('Training started for %s epochs.'  %(num_epochs))\n",
    "    epochs = []\n",
    "    accuracy_results = []\n",
    "    loss_results = []\n",
    "    best_loss = 10000 # Picking random high number to assure correct functionality\n",
    "    loss_iter = 0\n",
    "\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        for indx_batch, (batch, targets) in enumerate(train_loader):\n",
    "\n",
    "            output = model.forward(batch)\n",
    "\n",
    "            targets = targets.long()\n",
    "\n",
    "            loss = loss_function(output, targets)\n",
    "            \n",
    "            # Optional print of loss per batch\n",
    "            #print('Loss in batch %s is: %s' %(indx_batch, loss))\n",
    "        \n",
    "            # Perform back prop after each batch\n",
    "            loss = loss_function(output, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph = True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Perform evaluation after each epoch\n",
    "        epoch, loss_eval, accuracy_eval = evaluation(val_loader, model, epoch, loss_function)\n",
    "        epochs.append(epoch)\n",
    "        accuracy_results.append(accuracy_eval)\n",
    "        loss_results.append(loss_eval)\n",
    "        \n",
    "        if baseline == True:\n",
    "            best_loss, loss_iter = baseline_control(epoch, model, best_loss, loss_eval, loss_iter, max_loss_iter)\n",
    "        \n",
    "    dict_results = {\n",
    "        'model': model,\n",
    "        'epoch': epochs,\n",
    "        'loss_results': loss_results,\n",
    "        'accuracy_results':accuracy_results,\n",
    "        'best_loss': best_loss,\n",
    "        'loss_iter': loss_iter,\n",
    "    }\n",
    "    \n",
    "    #plot_results(epochs, loss_results, accuracy_results)\n",
    "    \n",
    "    return dict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
