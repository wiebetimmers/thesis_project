{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reservoir model - no full backpropagation\n",
    "\n",
    "- Using an echo state network, see summary for details. \n",
    "- Performing classification on the Digits dataset from sklearn.\n",
    "- Results measured in logg loss (sum) and accuracy. \n",
    "\n",
    "Questions i still have / feedback.\n",
    "- I very explicitly implemented the model as how it is stated on the planner. \n",
    "- As expected, the reservoir performs bad (after 5 epochs, accuracy around 10%) compared to the baseline RNN (90%) \n",
    "- It seems that the bias parameters are still trained in the reservoir model. Is this desirable, or should i also remove / turn training off for those parameters?\n",
    "- Maybe for the baseline -> use this model instead? With all parameters requires_grad = True ?\n",
    "- What parameters should be kept constant? (e.g. learning rate, momentum sgd, batch size ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import os, sys, tarfile\n",
    "import requests\n",
    "import shutil\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Digits Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == 'train':\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "            self.targets = digits.target[:1000]\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "            self.targets = digits.target[1000:1350]\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "            self.targets = digits.target[1350:]\n",
    "        self.transforms = transforms\n",
    "        self.target_names = digits.target_names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_x = self.data[idx]\n",
    "        sample_y = self.targets[idx]\n",
    "        if self.transforms:\n",
    "            sample_x = self.transforms(sample_x)\n",
    "        return (sample_x, sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliazing the data loaders for the digits dataset. \n",
    "\n",
    "train_data = Digits(mode='train')\n",
    "val_data = Digits(mode='val')\n",
    "test_data = Digits(mode='test')\n",
    "\n",
    "LABELS = train_data.target_names\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=50, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=50, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=50, shuffle=False)\n",
    "\n",
    "result_dir = 'results_reservoir_wiebe/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c744ddd580>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print an example digit and its according target label. - (digits dataset)\n",
    "\n",
    "print(train_data.targets[88])\n",
    "plottable_image = np.reshape(train_data.data[88], (8, 8))\n",
    "plt.imshow(plottable_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reservoir(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size):\n",
    "        super(Reservoir, self).__init__()\n",
    "        self.f_0 = nn.Softmax(dim=1)\n",
    "        self.f_t = nn.Softmax(dim=1)\n",
    "        self.f_y = nn.Softmax(dim=1)\n",
    "        \n",
    "        # Sample the initial weights from a uniform distribution - initialize the same as in the baseline model.\n",
    "        self.W_in = nn.Parameter(data = torch.zeros(reservoir_size, input_size, requires_grad=False))\n",
    "        self.W_in.data.uniform_(-0.01, 0.01)\n",
    "        \n",
    "        self.W_r = nn.Parameter(data = torch.zeros(reservoir_size, reservoir_size), requires_grad=False)\n",
    "        self.W_r.data.uniform_(-0.01, 0.01)\n",
    "        \n",
    "        self.W_out = nn.Parameter(data = torch.zeros(output_size, reservoir_size), requires_grad=True)\n",
    "        self.W_out.data.uniform_(-0.01, 0.01)\n",
    "        \n",
    "        self.U = nn.Parameter(data = torch.zeros(reservoir_size, input_size), requires_grad=False)\n",
    "        self.U.data.uniform_(-0.01, 0.01)\n",
    "        \n",
    "        # Layer only used for C_0, initial weight!\n",
    "        self.layer1 = torch.nn.Linear(input_size, reservoir_size, bias=True)\n",
    "        self.layer1.weight = self.W_in\n",
    "        #Making sure we do not calc the gradient of our input layer! only for output. \n",
    "        self.layer1.weight.requires_grad = False\n",
    "        \n",
    "        self.layer2 = torch.nn.Linear(reservoir_size, reservoir_size, bias=True)\n",
    "        self.layer2.weight = self.W_r\n",
    "        \n",
    "        self.layer3 = torch.nn.Linear(input_size, reservoir_size, bias=True)\n",
    "        self.layer3.weight = self.U\n",
    "        \n",
    "        self.layer4 = torch.nn.Linear(2*reservoir_size, output_size, bias=True)\n",
    "        self.layer4.weight = self.W_out\n",
    "\n",
    "    def forward(self, input_state, t, prev_c):\n",
    "        \n",
    "        # Prev_c = c at t - 1\n",
    "        \n",
    "        # If we have the first batch, calculate c_0 = f_0(W_in * x_t)\n",
    "        if t == 1:\n",
    "            prev_c = self.init_C(input_state)\n",
    "        \n",
    "        # Not the first batch? -> use output from previous state!\n",
    "        # W_r * c_t_1\n",
    "        output_lin_2 = self.layer2(prev_c)\n",
    "        \n",
    "        # U * x_t\n",
    "        output_lin_3 = self.layer3(input_state)\n",
    "        \n",
    "        # Calculate new c_t -  f_t (W_r * c_t-1 + U * x_t)\n",
    "        c_t = self.f_t(output_lin_2 + output_lin_3)\n",
    "        \n",
    "        # Calculate output - f_y ( W_out * c_t)\n",
    "        y = self.f_y(self.layer4(c_t))\n",
    "    \n",
    "        return y, c_t\n",
    "    \n",
    "    def init_C(self, input_state):\n",
    "        output_linear_layer1 = self.layer1(input_state)\n",
    "        c_0 = self.f_0(output_linear_layer1)\n",
    "        return c_0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that transforms the tensor output to a predicted target name. \n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return LABELS[category_i]\n",
    "\n",
    "# Plot both accuracy as log loss. \n",
    "def plot_results(epochs, loss, accuracy):\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    fig.suptitle('Results Reservoir - Only output is trained.')\n",
    "    ax1.set(ylabel='Loss')\n",
    "    ax2.set(ylabel='Accuracy', xlabel='Epochs')\n",
    "    \n",
    "    ax1.plot(epochs, loss)\n",
    "    ax2.plot(epochs, accuracy)\n",
    "    \n",
    "\n",
    "    plt.savefig('results_reservoir.png', bbox_inches='tight')\n",
    "    #plt.close()\n",
    "\n",
    "\n",
    "# Concatenating the results of all (64*)batches in the lists, calculating the total accuracy. \n",
    "def accuracy(pred_targets_list, gold_targets_list):\n",
    "    total_correct = 0\n",
    "    total_amount = 0\n",
    "    \n",
    "    zip_list = zip(pred_targets_list, gold_targets_list)\n",
    "    for pred_targets, gold_targets in zip_list:\n",
    "        total_correct += (pred_targets == gold_targets).float().sum()\n",
    "        total_amount += len(pred_targets)\n",
    "    \n",
    "    accuracy = 100 * total_correct / total_amount\n",
    "\n",
    "    return accuracy.item()\n",
    "\n",
    "# Evaluation -> used for validation and test set. \n",
    "def evaluation(val_loader, model, epoch, loss_function):\n",
    "    \n",
    "    #Evaluating our performance so far\n",
    "    model.eval()\n",
    "    \n",
    "    # Store all results in a list to calculate the accuracy. \n",
    "    pred_target_total_acc = []\n",
    "    target_total_acc = []\n",
    "    \n",
    "    # Initialize counters / c\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    prev_c = 0\n",
    "    t = 1\n",
    "    \n",
    "    # Iterating over the validation set batches, acquiring tensor formatted results. \n",
    "    for indx_batch, (batch, targets) in enumerate(val_loader):\n",
    "        output, new_c = model.forward(batch, t, prev_c)\n",
    "        pred_targets = np.array([])\n",
    "        for item in output:\n",
    "            pred_targets = np.append(pred_targets, categoryFromOutput(item))\n",
    "        pred_targets = torch.from_numpy(pred_targets).int()\n",
    "        \n",
    "        prev_c = new_c\n",
    "        \n",
    "        # Calculating loss\n",
    "        loss_t = loss_function(output, targets.long())\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + batch.shape[0]\n",
    "        \n",
    "        #Append the batch result to a list of all results\n",
    "        pred_target_total_acc.append(pred_targets)\n",
    "        target_total_acc.append(targets)\n",
    "    \n",
    "    # Store the loss corrected by its size\n",
    "    loss = loss / N   \n",
    "        \n",
    "    total_accuracy = accuracy(pred_target_total_acc, target_total_acc)\n",
    "    print('Epoch: %s - Loss of: %s - Accuracy of: %s' %(epoch, loss,total_accuracy))\n",
    "    \n",
    "    return epoch, loss, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_loader, val_loader, num_epochs, optimizer, loss_function, max_loss_iter):    \n",
    "    \n",
    "    print('Training started for %s epochs.'  %(num_epochs))\n",
    "    epochs = []\n",
    "    accuracy_results = []\n",
    "    loss_results = []\n",
    "    best_loss = 10000 # Picking random high number to assure correct functionality\n",
    "    loss_iter = 0\n",
    "\n",
    "    t = 1\n",
    "    prev_c = 0\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        for indx_batch, (batch, targets) in enumerate(train_loader):\n",
    "\n",
    "            output, new_c = model.forward(batch, t, prev_c)\n",
    "\n",
    "            targets = targets.long()\n",
    "            prev_c =  new_c\n",
    "\n",
    "            t += 1\n",
    "            loss = loss_function(output, targets)\n",
    "            \n",
    "            # Optional print of loss per batch\n",
    "            #print('Loss in batch %s is: %s' %(indx_batch, loss))\n",
    "        \n",
    "        # Perform back prop after each epoch\n",
    "        loss = loss_function(output, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Perform evaluation after each epoch\n",
    "        epoch, loss_eval, accuracy_eval = evaluation(val_loader, model, epoch, loss_function)\n",
    "        epochs.append(epoch)\n",
    "        accuracy_results.append(accuracy_eval)\n",
    "        loss_results.append(loss_eval)\n",
    "\n",
    "        if epoch == 0:\n",
    "            print('* Saving 1st epoch model *')\n",
    "            torch.save(model, 'trained_reservoir.model')\n",
    "            best_loss = loss_eval\n",
    "        else:\n",
    "            if loss_eval < best_loss:\n",
    "                print('* Saving new best model *')\n",
    "                torch.save(model, 'trained_reservoir.model')\n",
    "                best_loss = loss_eval\n",
    "                loss_iter = 0\n",
    "            else:\n",
    "                loss_iter += 1\n",
    "\n",
    "            # If loss has not improved for an arbitrary amount of epochs:\n",
    "        if loss_iter > max_loss_iter:\n",
    "            break\n",
    "\n",
    "    plot_results(epochs, loss_results, accuracy_results)\n",
    "\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 64\n",
    "reservoir_size = 128\n",
    "n_labels = 10\n",
    "lr_SGD = 0.0001\n",
    "momentum_SGD = 0.9\n",
    "n_epochs = 5\n",
    "max_loss_iter = 10\n",
    "batch_size=50\n",
    "\n",
    "model = Reservoir(input_size, reservoir_size, n_labels)\n",
    "\n",
    "# Using mini-batch gradient descent\n",
    "optimizer = optim.SGD([p for p in model.parameters() if p.requires_grad == True], lr=lr_SGD, momentum=momentum_SGD)\n",
    "loss_function = nn.NLLLoss(reduction='sum') # Mean is also possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_out\n",
      "layer1.bias\n",
      "layer2.bias\n",
      "layer3.bias\n",
      "layer4.bias\n"
     ]
    }
   ],
   "source": [
    "# Check all parameters that are trained: should only be W_out!\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started for 5 epochs.\n",
      "Epoch: 0 - Loss of: -0.10000923565455845 - Accuracy of: 10.0\n",
      "* Saving 1st epoch model *\n",
      "Epoch: 1 - Loss of: -0.10000926971435548 - Accuracy of: 10.0\n",
      "* Saving new best model *\n",
      "Epoch: 2 - Loss of: -0.10000930922372 - Accuracy of: 10.0\n",
      "* Saving new best model *\n",
      "Epoch: 3 - Loss of: -0.10000938143048968 - Accuracy of: 10.0\n",
      "* Saving new best model *\n",
      "Epoch: 4 - Loss of: -0.10000942093985421 - Accuracy of: 10.0\n",
      "* Saving new best model *\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_model = training(model, train_loader, val_loader, n_epochs, optimizer, loss_function, max_loss_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "      Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Linear-1             [1, 64]           8,320             128\n",
      "         Softmax-2            [1, 128]               0               0\n",
      "          Linear-3            [1, 128]          16,512             128\n",
      "          Linear-4             [1, 64]           8,320             128\n",
      "         Softmax-5            [1, 128]               0               0\n",
      "          Linear-6            [1, 128]           1,290           1,290\n",
      "         Softmax-7             [1, 10]               0               0\n",
      "=======================================================================\n",
      "Total params: 34,442\n",
      "Trainable params: 1,674\n",
      "Non-trainable params: 32,768\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Prev_c input is required, but not used in T = 1\n",
    "prev_c = 0\n",
    "print(summary(model, torch.zeros(1, 64), 1, prev_c, show_input=True, show_hierarchical=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: Final score - Loss of: -0.09692796818095299 - Accuracy of: 6.487695693969727\n"
     ]
    }
   ],
   "source": [
    "test_result = evaluation(test_loader, trained_model, 'Final score', loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
