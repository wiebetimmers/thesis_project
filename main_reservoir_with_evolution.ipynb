{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reservoir model - only output is trained\n",
    "\n",
    "- Implemented a recurrent reservoir model, see summary(model) below for details on the layers. \n",
    "- Performing classification on the Digits dataset and MNIST dataset\n",
    "- Results measured in logg loss (sum) and accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import os, sys, tarfile\n",
    "import requests\n",
    "import shutil\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "from pytorch_model_summary import summary\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Digits Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == 'train':\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "            self.targets = digits.target[:1000]\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "            self.targets = digits.target[1000:1350]\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "            self.targets = digits.target[1350:]\n",
    "        self.transforms = transforms\n",
    "        self.target_names = digits.target_names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_x = self.data[idx]\n",
    "        sample_y = self.targets[idx]\n",
    "        if self.transforms:\n",
    "            sample_x = self.transforms(sample_x)\n",
    "        return (sample_x, sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliazing the data loaders for the digits dataset. \n",
    "\n",
    "train_data_digits = Digits(mode='train')\n",
    "val_data_digits = Digits(mode='val')\n",
    "test_data_digits = Digits(mode='test')\n",
    "\n",
    "LABELS = train_data_digits.target_names\n",
    "\n",
    "train_loader_digits = DataLoader(train_data_digits, batch_size=50, shuffle=True)\n",
    "val_loader_digits = DataLoader(val_data_digits, batch_size=50, shuffle=False)\n",
    "test_loader_digits = DataLoader(test_data_digits, batch_size=50, shuffle=False)\n",
    "\n",
    "result_dir = 'results_baseline_wiebe/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x200d3192220>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print an example digit and its according target label. - (digits dataset)\n",
    "\n",
    "print(train_data_digits.targets[88])\n",
    "plottable_image = np.reshape(train_data_digits.data[88], (8, 8))\n",
    "plt.imshow(plottable_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MNIST Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(Dataset):\n",
    "    \"\"\"Complete MNIST dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        data_set_train = torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "        data_set_test = torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        \n",
    "        if mode == 'train':\n",
    "            for i in range(40000):\n",
    "                self.data.append(data_set_train[i][0].numpy())\n",
    "                self.targets.append(data_set_train[i][1])\n",
    "        elif mode == 'val':\n",
    "            for i in range(50000, 60000):\n",
    "                self.data.append(data_set_train[i][0].numpy())\n",
    "                self.targets.append(data_set_train[i][1])\n",
    "        else:\n",
    "            for i in range(len(data_set_test)):\n",
    "                self.data.append(data_set_test[i][0].numpy())\n",
    "                self.targets.append(data_set_test[i][1])\n",
    "        \n",
    "        self.targets = np.array(self.targets)\n",
    "        self.data = np.array(self.data)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_x = self.data[idx]\n",
    "        sample_y = self.targets[idx]\n",
    "        if self.transforms:\n",
    "            sample_x = self.transforms(sample_x)\n",
    "        return (sample_x, sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the MNIST dataset - (takes longer to load than Digits!, 6)\n",
    "train_data_mnist = MNIST(mode='train')\n",
    "val_data_mnist = MNIST(mode='val')\n",
    "test_data_mnist = MNIST(mode='test')\n",
    "\n",
    "train_loader_mnist = DataLoader(train_data_mnist, batch_size=50, shuffle=True)\n",
    "val_loader_mnist = DataLoader(val_data_mnist, batch_size=50, shuffle=True)\n",
    "test_loader_mnist = DataLoader(test_data_mnist, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x200d2e60100>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print an example MNIST digit and its according target label. - (digits dataset)\n",
    "\n",
    "print(val_data_mnist.targets[1900])\n",
    "plottable_image = np.reshape(val_data_mnist.data[1900], (28, 28))\n",
    "plt.imshow(plottable_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reservoir(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size, T, dataset = None):\n",
    "        super(Reservoir, self).__init__()\n",
    "        \n",
    "        # Activation functions\n",
    "        self.f_0 = nn.Tanh()\n",
    "        self.f_t = nn.ReLU(inplace=False)\n",
    "        self.f_y = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        # Amount of timesteps / recurrent layers\n",
    "        self.T = T\n",
    "        \n",
    "        # Initialize the weights & layers\n",
    "        self.initWeights(input_size, reservoir_size, output_size)\n",
    "        self.initLayers(input_size, reservoir_size, output_size)\n",
    "        \n",
    "        # Boolean\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        used_input = input\n",
    "        \n",
    "        # Squeeze the used input in 2 dims if we use the MNIST dataset.\n",
    "        if self.dataset == 'MNIST':\n",
    "            three_d_tensor = used_input.squeeze(1)\n",
    "            used_input = three_d_tensor.contiguous().view(three_d_tensor.size()[0], -1)  # 28 * 28 pixels = 784\n",
    "        \n",
    "        # Calculate c_0\n",
    "        c = self.f_0(self.layer1(used_input))\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            # c_t =  f_t (W_r * c_t-1 + U * x_t)\n",
    "            c = self.f_t(self.layer2(c) + self.layer3(used_input))\n",
    "        \n",
    "        # Calculate y = f_y ( W_out * c_t)\n",
    "        y = self.f_y(self.layer4(c))\n",
    "    \n",
    "        return y\n",
    "    \n",
    "    def initWeights(self, input_size, reservoir_size, output_size):\n",
    "        \n",
    "        # Sample the initial weights from a uniform distribution - initialize the same as in the baseline model.\n",
    "        self.W_in = nn.Parameter(data = torch.zeros(reservoir_size, input_size, requires_grad=False))\n",
    "        self.W_in.data.uniform_(-0.01, 0.01)\n",
    "        \n",
    "        self.W_r = nn.Parameter(data = torch.zeros(reservoir_size, reservoir_size), requires_grad=False)\n",
    "        self.W_r.data.uniform_(-0.01, 0.01)\n",
    "        \n",
    "        self.W_out = nn.Parameter(data = torch.zeros(output_size, reservoir_size), requires_grad=True)\n",
    "        self.W_out.data.uniform_(-0.01, 0.01)\n",
    "        \n",
    "        self.U = nn.Parameter(data = torch.zeros(reservoir_size, input_size), requires_grad=False)\n",
    "        self.U.data.uniform_(-0.01, 0.01)\n",
    "        return\n",
    "    \n",
    "    def initLayers(self, input_size, reservoir_size, output_size):\n",
    "        # Input layer\n",
    "        self.layer1 = torch.nn.Linear(input_size, reservoir_size, bias=True)\n",
    "        self.layer1.weight = self.W_in\n",
    "        self.layer1.weight.requires_grad = False\n",
    "        self.layer1.bias.requires_grad = False\n",
    "        \n",
    "        # Recurrent layer\n",
    "        self.layer2 = torch.nn.Linear(reservoir_size, reservoir_size, bias=True)\n",
    "        self.layer2.weight = self.W_r\n",
    "        self.layer2.bias.requires_grad = False\n",
    "        self.layer3 = torch.nn.Linear(input_size, reservoir_size, bias=True)\n",
    "        self.layer3.weight = self.U\n",
    "        self.layer3.bias.requires_grad = False\n",
    "        \n",
    "        # Output layer\n",
    "        self.layer4 = torch.nn.Linear(reservoir_size, output_size, bias=True)\n",
    "        self.layer4.weight = self.W_out\n",
    "        self.layer4.bias.requires_grad = True\n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that transforms the tensor output to a predicted target name. \n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return LABELS[category_i]\n",
    "\n",
    "# Plot both accuracy as log loss. \n",
    "def plot_results(epochs, loss, accuracy):\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    fig.suptitle('Results Reservoir - Only output is trained.')\n",
    "    ax1.set(ylabel='Loss')\n",
    "    ax2.set(ylabel='Accuracy', xlabel='Epochs')\n",
    "    \n",
    "    ax1.plot(epochs, loss)\n",
    "    ax2.plot(epochs, accuracy)\n",
    "    \n",
    "\n",
    "    plt.savefig('results_reservoir.png', bbox_inches='tight')\n",
    "    #plt.close()\n",
    "\n",
    "\n",
    "# Concatenating the results of all (64*)batches in the lists, calculating the total accuracy. \n",
    "def accuracy(pred_targets_list, gold_targets_list):\n",
    "    total_correct = 0\n",
    "    total_amount = 0\n",
    "    \n",
    "    zip_list = zip(pred_targets_list, gold_targets_list)\n",
    "    for pred_targets, gold_targets in zip_list:\n",
    "        total_correct += (pred_targets == gold_targets).float().sum()\n",
    "        total_amount += len(pred_targets)\n",
    "    \n",
    "    accuracy = 100 * total_correct / total_amount\n",
    "\n",
    "    return accuracy.item()\n",
    "\n",
    "# Evaluation -> used for validation and test set. \n",
    "def evaluation(val_loader, model, epoch, loss_function):\n",
    "    \n",
    "    #Evaluating our performance so far\n",
    "    #model.eval()\n",
    "    \n",
    "    # Store all results in a list to calculate the accuracy. \n",
    "    pred_target_total_acc = []\n",
    "    target_total_acc = []\n",
    "    \n",
    "    # Initialize counters / c\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    \n",
    "    # Iterating over the validation set batches, acquiring tensor formatted results. \n",
    "    for indx_batch, (batch, targets) in enumerate(val_loader):\n",
    "        output = model.forward(batch)\n",
    "        pred_targets = np.array([])\n",
    "        for item in output:\n",
    "            pred_targets = np.append(pred_targets, categoryFromOutput(item))\n",
    "        pred_targets = torch.from_numpy(pred_targets).int()\n",
    "        \n",
    "        # Calculating loss\n",
    "        loss_t = loss_function(output, targets.long())\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + batch.shape[0]\n",
    "        \n",
    "        #Append the batch result to a list of all results\n",
    "        pred_target_total_acc.append(pred_targets)\n",
    "        target_total_acc.append(targets)\n",
    "    \n",
    "    # Store the loss corrected by its size\n",
    "    loss = loss / N   \n",
    "        \n",
    "    total_accuracy = accuracy(pred_target_total_acc, target_total_acc)\n",
    "    print('Epoch: %s - Loss of: %s - Accuracy of: %s' %(epoch, loss,total_accuracy))\n",
    "    \n",
    "    return epoch, loss, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_loader, val_loader, num_epochs, optimizer, loss_function, max_loss_iter):    \n",
    "    \n",
    "    print('Training started for %s epochs.'  %(num_epochs))\n",
    "    epochs = []\n",
    "    accuracy_results = []\n",
    "    loss_results = []\n",
    "    best_loss = 10000 # Picking random high number to assure correct functionality\n",
    "    loss_iter = 0\n",
    "\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        for indx_batch, (batch, targets) in enumerate(train_loader):\n",
    "\n",
    "            output = model.forward(batch)\n",
    "\n",
    "            targets = targets.long()\n",
    "\n",
    "            loss = loss_function(output, targets)\n",
    "            \n",
    "            # Optional print of loss per batch\n",
    "            #print('Loss in batch %s is: %s' %(indx_batch, loss))\n",
    "        \n",
    "            # Perform back prop after each batch\n",
    "            loss = loss_function(output, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph = True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Perform evaluation after each epoch\n",
    "        epoch, loss_eval, accuracy_eval = evaluation(val_loader, model, epoch, loss_function)\n",
    "        epochs.append(epoch)\n",
    "        accuracy_results.append(accuracy_eval)\n",
    "        loss_results.append(loss_eval)\n",
    "\n",
    "        if epoch == 0:\n",
    "            print('* Saving 1st epoch model *')\n",
    "            torch.save(model, 'trained_reservoir.model')\n",
    "            best_loss = loss_eval\n",
    "        else:\n",
    "            if loss_eval < best_loss:\n",
    "                print('* Saving new best model *')\n",
    "                torch.save(model, 'trained_reservoir.model')\n",
    "                best_loss = loss_eval\n",
    "                loss_iter = 0\n",
    "            else:\n",
    "                loss_iter += 1\n",
    "\n",
    "            # If loss has not improved for an arbitrary amount of epochs:\n",
    "        if loss_iter > max_loss_iter:\n",
    "            break\n",
    "\n",
    "    dict_results = {\n",
    "        'model': model,\n",
    "        'epoch': epochs,\n",
    "        'loss_results': loss_results,\n",
    "        'accuracy_results':accuracy_results,\n",
    "        'best_loss': best_loss,\n",
    "        'loss_iter': loss_iter,\n",
    "    }\n",
    "    \n",
    "    #plot_results(epochs, loss_results, accuracy_results)\n",
    "    \n",
    "    return dict_results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size_digits = 64  # 8 * 8 pixels\n",
    "input_size_mnist = 784  # 28 * 28 pixels\n",
    "reservoir_size = 128\n",
    "n_labels = 10\n",
    "lr_SGD = 0.0001\n",
    "momentum_SGD = 0.9\n",
    "n_epochs = 2\n",
    "max_loss_iter = 10\n",
    "batch_size= 50\n",
    "T = 5\n",
    "\n",
    "population_size = 5\n",
    "generations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EA(object):\n",
    "    def __init__(self,  population_size, val_loader, loss_function):\n",
    "        self.population_size = population_size\n",
    "        self.val_loader = val_loader\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def fitness(self, population):\n",
    "        for reservoir in population:\n",
    "            epoch, loss, total_accuracy = evaluation(self.val_loader, \n",
    "                                                     reservoir['model'], \n",
    "                                                     reservoir['epoch'][-1]+1, \n",
    "                                                     loss_function)\n",
    "            reservoir['epoch'].append(epoch)\n",
    "            reservoir['loss_results'].append(loss)\n",
    "            reservoir['accuracy_results'].append(total_accuracy)\n",
    "            \n",
    "            # If we find a new best model, save it.\n",
    "            # Still have to fine tune this , make a directory for all the models. \n",
    "            if loss < reservoir['best_loss']:\n",
    "                print('* Saving new best model *')\n",
    "                torch.save(reservoir['model'], 'trained_reservoir.model')\n",
    "                reservoir['best_loss'] = loss\n",
    "                reservoir['loss_iter'] = 0\n",
    "            else:\n",
    "                reservoir['loss_iter'] += 1\n",
    "\n",
    "        return population\n",
    "\n",
    "    def mutation(self, population):\n",
    "        childs = copy.deepcopy(population)\n",
    "        \n",
    "        for reservoir in childs:\n",
    "            mutation_value = random.uniform(-0.1, 0.1)\n",
    "            reservoir['model'].W_in += mutation_value\n",
    "            reservoir['model'].W_r += mutation_value\n",
    "            reservoir['model'].U += mutation_value\n",
    "            \n",
    "            # We have to turn off requires grad,\n",
    "            # because pytorch does not allow inplace mutations on tensors which are used for backprop.\n",
    "            # See https://discuss.pytorch.org/t/leaf-variable-was-used-in-an-inplace-operation/308/2 .\n",
    "            reservoir['model'].W_out.requires_grad = False\n",
    "            reservoir['model'].W_out += mutation_value\n",
    "        \n",
    "        return population, childs\n",
    "\n",
    "    def recombination(self):\n",
    "        return\n",
    "\n",
    "    def selection(self):\n",
    "        # Different type of selections possible. \n",
    "        returns\n",
    "    \n",
    "    def step(self, population):\n",
    "        parents, childs = self.mutation(population)\n",
    "        #population = self.recombination(population)\n",
    "        print('Parents - no mutation - nothing')\n",
    "        fitness = self.fitness(parents)\n",
    "        print('Childs - mutation')\n",
    "        fitness = self.fitness(childs)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started for 2 epochs.\n",
      "Epoch: 0 - Loss of: 2.2610876028878346 - Accuracy of: 20.285715103149414\n",
      "* Saving 1st epoch model *\n",
      "Epoch: 1 - Loss of: 2.1970006452287945 - Accuracy of: 50.28571319580078\n",
      "* Saving new best model *\n",
      "Training started for 2 epochs.\n",
      "Epoch: 0 - Loss of: 2.247564435686384 - Accuracy of: 33.42856979370117\n",
      "* Saving 1st epoch model *\n",
      "Epoch: 1 - Loss of: 2.1720805576869417 - Accuracy of: 73.14286041259766\n",
      "* Saving new best model *\n",
      "Training started for 2 epochs.\n",
      "Epoch: 0 - Loss of: 2.2489808000837055 - Accuracy of: 42.28571319580078\n",
      "* Saving 1st epoch model *\n",
      "Epoch: 1 - Loss of: 2.1697315979003906 - Accuracy of: 48.57143020629883\n",
      "* Saving new best model *\n",
      "Training started for 2 epochs.\n",
      "Epoch: 0 - Loss of: 2.2517857360839844 - Accuracy of: 43.71428680419922\n",
      "* Saving 1st epoch model *\n",
      "Epoch: 1 - Loss of: 2.1740226527622766 - Accuracy of: 77.71428680419922\n",
      "* Saving new best model *\n",
      "Training started for 2 epochs.\n",
      "Epoch: 0 - Loss of: 2.2651678248814173 - Accuracy of: 41.71428680419922\n",
      "* Saving 1st epoch model *\n",
      "Epoch: 1 - Loss of: 2.205953107561384 - Accuracy of: 62.0\n",
      "* Saving new best model *\n"
     ]
    }
   ],
   "source": [
    "# Initialize population\n",
    "model_set_digits = []\n",
    "\n",
    "for i in range(population_size):\n",
    "    model_digits = Reservoir(input_size_digits, reservoir_size, n_labels, T, dataset = 'Digits')\n",
    "    optimizer_digits = optim.SGD([p for p in model_digits.parameters() if p.requires_grad == True], lr=lr_SGD, momentum=momentum_SGD)\n",
    "    loss_function = nn.NLLLoss(reduction='sum') # Mean is also possible.\n",
    "    trained_model_digits = training(model_digits, train_loader_digits, val_loader_digits, n_epochs, optimizer_digits, loss_function, max_loss_iter)\n",
    "    model_set_digits.append(trained_model_digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parents - no mutation - nothing\n",
      "Epoch: 2 - Loss of: 2.1970006452287945 - Accuracy of: 50.28571319580078\n",
      "Epoch: 2 - Loss of: 2.1720805576869417 - Accuracy of: 73.14286041259766\n",
      "Epoch: 2 - Loss of: 2.1697315979003906 - Accuracy of: 48.57143020629883\n",
      "Epoch: 2 - Loss of: 2.1740226527622766 - Accuracy of: 77.71428680419922\n",
      "Epoch: 2 - Loss of: 2.205953107561384 - Accuracy of: 62.0\n",
      "Childs - mutation\n",
      "Epoch: 2 - Loss of: 2.3035292489188057 - Accuracy of: 10.285714149475098\n",
      "Epoch: 2 - Loss of: 2.262464839390346 - Accuracy of: 32.0\n",
      "Epoch: 2 - Loss of: 2.302566637311663 - Accuracy of: 10.285714149475098\n",
      "Epoch: 2 - Loss of: 2.3036024257114955 - Accuracy of: 10.0\n",
      "Epoch: 2 - Loss of: 2.2046432277134485 - Accuracy of: 25.428571701049805\n",
      "* Saving new best model *\n"
     ]
    }
   ],
   "source": [
    "# Performing one evolution step, 3rd epoch, only mutation, no selection or recombination yet\n",
    "ea = EA(population_size, val_loader_digits, loss_function)\n",
    "    \n",
    "ea.step(model_set_digits)\n",
    "#for i in range(generations):\n",
    "    #ea.step(model_set_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started for 2 epochs.\n",
      "Epoch: 0 - Loss of: 1.7506878425598145 - Accuracy of: 68.9800033569336\n",
      "* Saving 1st epoch model *\n",
      "Epoch: 1 - Loss of: 1.4423225769042969 - Accuracy of: 73.58999633789062\n",
      "* Saving new best model *\n"
     ]
    }
   ],
   "source": [
    "model_mnist = Reservoir(input_size_mnist, reservoir_size, n_labels, T, dataset = 'MNIST')\n",
    "optimizer_mnist = optim.SGD([p for p in model_mnist.parameters() if p.requires_grad == True], lr=lr_SGD, momentum=momentum_SGD)\n",
    "loss_function = nn.NLLLoss(reduction='sum') # Mean is also possible.\n",
    "trained_model_mnist = training(model_mnist, train_loader_mnist, val_loader_mnist, n_epochs, optimizer_mnist, loss_function, max_loss_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "      Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Linear-1             [1, 64]           8,320               0\n",
      "            Tanh-2            [1, 128]               0               0\n",
      "          Linear-3            [1, 128]          16,512               0\n",
      "          Linear-4             [1, 64]           8,320               0\n",
      "            ReLU-5            [1, 128]               0               0\n",
      "          Linear-6            [1, 128]          16,512               0\n",
      "          Linear-7             [1, 64]           8,320               0\n",
      "            ReLU-8            [1, 128]               0               0\n",
      "          Linear-9            [1, 128]          16,512               0\n",
      "         Linear-10             [1, 64]           8,320               0\n",
      "           ReLU-11            [1, 128]               0               0\n",
      "         Linear-12            [1, 128]          16,512               0\n",
      "         Linear-13             [1, 64]           8,320               0\n",
      "           ReLU-14            [1, 128]               0               0\n",
      "         Linear-15            [1, 128]          16,512               0\n",
      "         Linear-16             [1, 64]           8,320               0\n",
      "           ReLU-17            [1, 128]               0               0\n",
      "         Linear-18            [1, 128]           1,290           1,290\n",
      "     LogSoftmax-19             [1, 10]               0               0\n",
      "=======================================================================\n",
      "Total params: 133,770\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 132,480\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(model_digits, torch.zeros(1, 64), show_input=True, show_hierarchical=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'forward'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-a54f39158e42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_result_digits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader_digits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrained_model_digits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Final score Digits'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-112-0fa28c896f55>\u001b[0m in \u001b[0;36mevaluation\u001b[1;34m(val_loader, model, epoch, loss_function)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# Iterating over the validation set batches, acquiring tensor formatted results.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mpred_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'forward'"
     ]
    }
   ],
   "source": [
    "test_result_digits = evaluation(test_loader_digits, trained_model_digits, 'Final score Digits', loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-34a7c2825cca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_result_mnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader_mnist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrained_model_mnist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Final score MNIST'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-102-8065c6aa18ea>\u001b[0m in \u001b[0;36mevaluation\u001b[1;34m(val_loader, model, epoch, loss_function)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m#Evaluating our performance so far\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# Store all results in a list to calculate the accuracy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "test_result_mnist = evaluation(test_loader_mnist, trained_model_mnist, 'Final score MNIST', loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
